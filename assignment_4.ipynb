{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa47c9a9-a781-4eec-ad24-11070c5154cb",
   "metadata": {},
   "source": [
    "Write a Python program to scrape all available books from the website (https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe, legal, no anti-bot). For each book, extract the following details:\n",
    "\n",
    "1. Title\n",
    "2. Price\n",
    "3. Availability (In stock / Out of stock)\n",
    "4. Star Rating (One, Two, Three, Four, Five)\n",
    "\n",
    "Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9310ed01-6d1a-4d16-961a-73427b4e2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd72b8d-7120-4390-adaa-ea14d5a28454",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://books.toscrape.com/catalogue/\"\n",
    "TOTAL_PAGES = 50\n",
    "\n",
    "def scrape_page(page_no):\n",
    "    books_list = []\n",
    "    url = f\"{BASE_URL}page-{page_no}.html\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    items = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    if len(items) == 0:\n",
    "        return []\n",
    "\n",
    "    for item in items:\n",
    "        t = item.h3.a[\"title\"] if item.h3 and item.h3.a else None\n",
    "        p = item.find(\"p\", class_=\"price_color\")\n",
    "        price = p.get_text(strip=True) if p else None\n",
    "\n",
    "        stock = item.find(\"p\", class_=\"instock availability\")\n",
    "        avail = stock.get_text(strip=True) if stock else None\n",
    "\n",
    "        rating_tag = item.find(\"p\", class_=\"star-rating\")\n",
    "        rating = rating_tag[\"class\"][1] if rating_tag and len(rating_tag[\"class\"]) > 1 else None\n",
    "\n",
    "        books_list.append({\n",
    "            \"Title\": t or \"NaN\",\n",
    "            \"Price\": price or \"NaN\",\n",
    "            \"Availability\": avail or \"NaN\",\n",
    "            \"Star Rating\": rating or \"NaN\"\n",
    "        })\n",
    "    return books_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccf64f2-5bb8-482f-8c39-2a0b12e0788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>Â£51.77</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>Â£53.74</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>Â£50.10</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>Â£54.23</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n",
       "      <td>Â£55.53</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)</td>\n",
       "      <td>Â£57.06</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n",
       "      <td>Â£16.97</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1st to Die (Women's Murder Club #1)</td>\n",
       "      <td>Â£53.98</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1,000 Places to See Before You Die</td>\n",
       "      <td>Â£26.08</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title    Price Availability  \\\n",
       "0                                 A Light in the Attic  Â£51.77     In stock   \n",
       "1                                   Tipping the Velvet  Â£53.74     In stock   \n",
       "2                                           Soumission  Â£50.10     In stock   \n",
       "3                                        Sharp Objects  Â£47.82     In stock   \n",
       "4                Sapiens: A Brief History of Humankind  Â£54.23     In stock   \n",
       "..                                                 ...      ...          ...   \n",
       "995  Alice in Wonderland (Alice's Adventures in Won...  Â£55.53     In stock   \n",
       "996   Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)  Â£57.06     In stock   \n",
       "997  A Spy's Devotion (The Regency Spies of London #1)  Â£16.97     In stock   \n",
       "998                1st to Die (Women's Murder Club #1)  Â£53.98     In stock   \n",
       "999                 1,000 Places to See Before You Die  Â£26.08     In stock   \n",
       "\n",
       "    Star Rating  \n",
       "0         Three  \n",
       "1           One  \n",
       "2           One  \n",
       "3          Four  \n",
       "4          Five  \n",
       "..          ...  \n",
       "995         One  \n",
       "996        Four  \n",
       "997        Five  \n",
       "998         One  \n",
       "999        Five  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "for page in range(1, TOTAL_PAGES + 1):\n",
    "    all_data.extend(scrape_page(page))\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "if not df.empty:\n",
    "    df.to_csv('book_data.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081535b0-f926-4cb3-b8d1-aa32f6e0cb67",
   "metadata": {},
   "source": [
    "Write a Python program to scrape the IMDB Top 250 Movies list\n",
    "(https://www.imdb.com/chart/top/) . For each movie, extract the following details:\n",
    "\n",
    "1. Rank (1–250)\n",
    "2. Movie Title\n",
    "3. Year of Release\n",
    "4. IMDB Rating\n",
    "\n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c48cf124-0ded-4fa2-ab93-97782e9b23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "list_container = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.ipc-metadata-list\"))\n",
    ")\n",
    "movies = list_container.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "movies_data = []\n",
    "for movie_item in movies:\n",
    "    title_text = movie_item.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\").text\n",
    "    rank_str, title = title_text.split(\". \", 1)\n",
    "\n",
    "    metadata_items = movie_item.find_elements(By.CSS_SELECTOR, \"span.cli-title-metadata-item\")\n",
    "    year_str = metadata_items[0].text\n",
    "\n",
    "    rating_str = movie_item.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star\").text.split(\"\\n\")[0]\n",
    "\n",
    "    movies_data.append({\n",
    "        \"Rank\": int(rank_str),\n",
    "        \"Movie Title\": title,\n",
    "        \"Year of Release\": int(year_str),\n",
    "        \"IMDB Rating\": float(rating_str)\n",
    "    })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(movies_data)\n",
    "df = df.sort_values(by=\"Rank\").reset_index(drop=True)\n",
    "df.to_csv(\"imdb_top250.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6e4ae-307e-4769-b410-7fadbbda5ddf",
   "metadata": {},
   "source": [
    "Write a Python program to scrape the weather information for top world cities from the\n",
    "given website (https://www.timeanddate.com/weather/) . For each city, extract the following\n",
    "details:\n",
    "\n",
    "1. City Name\n",
    "2. Temperature\n",
    "3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)\n",
    "\n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19adb689-0315-4ea0-98da-7b5ddd1f342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_temp_to_float(temp_str):\n",
    "    t = temp_str.replace(\"°C\", \"\").replace(\"°F\", \"\").strip()\n",
    "    t = t.replace(\"\\u00a0\", \"\").replace(\"\\xa0\", \"\")\n",
    "    return float(t)\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "cells = soup.find_all(\"td\")\n",
    "data = []\n",
    "city_name, condition = None, \"\"\n",
    "\n",
    "for idx, cell in enumerate(cells):\n",
    "    if cell.find(\"a\"):\n",
    "        city_name = cell.get_text(strip=True)\n",
    "        condition = \"\"\n",
    "\n",
    "        for step in range(1, 3):\n",
    "            if idx + step < len(cells):\n",
    "                img_tag = cells[idx + step].find(\"img\")\n",
    "                if img_tag and img_tag.get(\"alt\"):\n",
    "                    condition = img_tag[\"alt\"]\n",
    "                    break\n",
    "\n",
    "    elif \"rbi\" in cell.get(\"class\", []) and city_name:\n",
    "        temp_val = cell.get_text(strip=True)\n",
    "        try:\n",
    "            temp_float = parse_temp_to_float(temp_val)\n",
    "        except Exception as e:\n",
    "            temp_float = None\n",
    "\n",
    "        data.append({\n",
    "            \"City\": city_name,\n",
    "            \"Temperature\": temp_float,\n",
    "            \"Condition\": condition\n",
    "        })\n",
    "        city_name, condition = None, \"\"\n",
    "\n",
    "df_weather = pd.DataFrame(data)\n",
    "df_weather.to_csv(\"weather.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
